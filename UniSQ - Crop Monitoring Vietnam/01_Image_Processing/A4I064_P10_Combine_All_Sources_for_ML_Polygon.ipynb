{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55d704b-fc8e-4784-b4ba-2417c9cfb7f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This code combines the cropwise csv files previously generated from the satellite image and drones. It reads four sets of input files as csv - first from the combined GEE data named as combined_crop.csv (eg. combined_mangopolygon.csv), second from the drone data named as crop_Polygon_Drone_Extract.csv (eg. Mango_Polygon_Drone_Extract.csv), third from the Landsat derived VI tiffs named as Crop_Polygon_Landsat_Extract.csv (eg. Mango_Polygon_Landsat_Extract.csv) and the fourth as Crop_Polygon_Sentinel2_Extract.csv (eg. Mango_Polygon_Sentinel2_Extract.csv). As the output, the code will generate three combined csv files by crop which are saved in the \"output_folder\" folder. The file names are saved as A4I06_fruit_four_combined_polygon_data_for_ML.csv (eg. A4I06_dragonfruit_four_combined_polygon_data_for_ML.csv). All the calculations are done locally and no temporary files are created during the calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "98b00138-955f-4df3-8756-6721d6a48bb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment name: A4I064-ML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# This gives the name of the environment directory\n",
    "print(\"Environment name:\", os.path.basename(sys.prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "24c4db4e-f764-4052-8844-c78e52d047f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is already installed.\n",
      "All packages have been installed!\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages, if needed\n",
    "\n",
    "required_packages = [\"pandas\"]\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package if package != \"scikit-learn\" else \"sklearn\")\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"All packages have been installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10474639-cbec-4090-a886-f2f04e534670",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e468e84d-115d-4cc6-96c7-8e8f2f18f161",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select one crop at a time\n",
    "crop_names = [\"Rice\", \"Mango\", \"Dragonfruit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3fb0de49-189b-4250-a616-40acded77b91",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input and output folders\n",
    "input_folder_satellite = r\"C:\\Users\\U8019357\\UniSQ\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\2 - ML\\Raw Data\\GEE_VIs\"\n",
    "input_folder_landsat = r\"C:\\Users\\U8019357\\UniSQ\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\2 - ML\\Raw Data\\Landsat_VIs\"\n",
    "input_folder_sentinel2 = r\"C:\\Users\\U8019357\\UniSQ\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\2 - ML\\Raw Data\\Sentinel2_VIs\"\n",
    "input_folder_drone = r\"C:\\Users\\U8019357\\UniSQ\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\2 - ML\\Raw Data\\Drone_VIs\"\n",
    "\n",
    "# Output folder to save combined VIs\n",
    "output_folder = r\"C:\\Users\\U8019357\\UniSQ\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\2 - ML\\Processed Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0267e385-7154-4301-b93a-822a6d3001a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to find CSV files containing the crop name AND \"polygon\" in the folder\n",
    "def find_crop_csv(folder, crop_name):\n",
    "    files = os.listdir(folder)\n",
    "    csv_files = [\n",
    "        f for f in files \n",
    "        if f.lower().endswith('.csv') \n",
    "           and crop_name.lower() in f.lower() \n",
    "           and \"polygon\" in f.lower()  # only polygon files\n",
    "           and \"minmaxmean\" not in f.lower()\n",
    "    ]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV file found for crop '{crop_name}' with 'polygon' in {os.path.basename(folder)}\")\n",
    "        return None\n",
    "    elif len(csv_files) > 1:\n",
    "        print(f\"Multiple CSV files found for crop '{crop_name}' with 'polygon' in {os.path.basename(folder)}:\\n {csv_files}\\n\")\n",
    "    \n",
    "    # Return the first matching file\n",
    "    return os.path.join(folder, csv_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d35df4b-dd3e-4b1c-9b1b-0d2e6eda045f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function to standardize and parse dates robustly\n",
    "def process_dates(df, source_name, date_format=None, dayfirst=True, crop_name=None):\n",
    "    if df.empty:\n",
    "        print(f\"No rows in {source_name} data.\")\n",
    "        return df\n",
    "\n",
    "    # Standardise 'Date' column name (case/whitespace-insensitive)\n",
    "    date_col = None\n",
    "    for col in df.columns:\n",
    "        if col.strip().lower() == 'date':\n",
    "            date_col = col\n",
    "            break\n",
    "    if date_col is None:\n",
    "        print(f\"No 'Date' column in {source_name} data.\")\n",
    "        return df\n",
    "    if date_col != 'Date':\n",
    "        df.rename(columns={date_col: 'Date'}, inplace=True)\n",
    "\n",
    "    # Work on a clean string view of the Date column\n",
    "    s = df['Date'].astype(str).str.strip()\n",
    "\n",
    "    # 1) Remove any time suffix like \" 00:00:00\", \"T00:00:00Z\", milliseconds, timezone, etc.\n",
    "    s_no_time = s.str.replace(r'[T ]\\d{2}:\\d{2}:\\d{2}(\\.\\d+)?(Z|[+-]\\d{2}:\\d{2})?$', '', regex=True)\n",
    "\n",
    "    # 2) Drop trailing \".0\" (common if dates came in as floats, e.g., 20240508.0 or 45123.0)\n",
    "    s_no_time = s_no_time.str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "    # Prepare result container\n",
    "    parsed = pd.Series(pd.NaT, index=df.index, dtype='datetime64[ns]')\n",
    "\n",
    "    # 3) Handle YYYYMMDD (exactly 8 digits)\n",
    "    mask_ymd8 = s_no_time.str.fullmatch(r'\\d{8}')\n",
    "    if mask_ymd8.any():\n",
    "        parsed.loc[mask_ymd8] = pd.to_datetime(s_no_time.loc[mask_ymd8], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "    # 4) Handle Excel serial dates (5â€“6 digits; Excel epoch 1899-12-30)\n",
    "    #    Typical modern serials are ~ 40kâ€“80k. Keep it broad but safe.\n",
    "    mask_excel = s_no_time.str.fullmatch(r'\\d{5,6}')\n",
    "    if mask_excel.any():\n",
    "        serial = s_no_time.loc[mask_excel].astype(float).astype('Int64')\n",
    "        # filter to a sane range to avoid misclassifying short yyyymm-like strings\n",
    "        ok = serial.between(20000, 90000)\n",
    "        serial_ok = serial[ok].astype(int)\n",
    "        parsed.loc[serial_ok.index] = pd.to_datetime('1899-12-30') + pd.to_timedelta(serial_ok, unit='D')\n",
    "\n",
    "    # 5) Remaining strings â†’ robust mixed parse (or explicit format if provided)\n",
    "    remaining = parsed.isna()\n",
    "    if remaining.any():\n",
    "        try:\n",
    "            if date_format:\n",
    "                parsed.loc[remaining] = pd.to_datetime(s_no_time.loc[remaining], format=date_format, errors='coerce')\n",
    "            else:\n",
    "                # Pandas 2.0+: infer per element\n",
    "                parsed.loc[remaining] = pd.to_datetime(s_no_time.loc[remaining], format='mixed', dayfirst=dayfirst, errors='coerce')\n",
    "        except TypeError:\n",
    "            # Older pandas without format='mixed'\n",
    "            parsed.loc[remaining] = pd.to_datetime(s_no_time.loc[remaining], dayfirst=dayfirst, errors='coerce')\n",
    "\n",
    "    df['Date'] = parsed\n",
    "\n",
    "    # Report issues (show a few offending raw values to help diagnose)\n",
    "    missing = df['Date'].isna().sum()\n",
    "    if missing > 0:\n",
    "        bad_examples = s.loc[df['Date'].isna()].dropna().unique()[:5]\n",
    "        print(f\"Warning: {missing} invalid 'Date' values in {source_name} for crop {crop_name}. Examples: {bad_examples}\")\n",
    "\n",
    "        # ðŸ‘‡ Add this block here\n",
    "        bad_rows = df[df['Date'].isna()].copy()\n",
    "        if not bad_rows.empty:\n",
    "            print(bad_rows[['Date']].head())\n",
    "            # Optional: save them for inspection\n",
    "            # bad_rows.to_csv(os.path.join(output_folder,\n",
    "            #     f'bad_dates_{source_name}_{crop_name}.csv'), index=False)\n",
    "    else:\n",
    "        print(f\"All 'Date' values parsed successfully in {source_name} data.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46d8cecd-337f-49bd-b30f-0f256114f1f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing crop: Rice\n",
      "\n",
      "Multiple CSV files found for crop 'Rice' with 'polygon' in Landsat_VIs:\n",
      " ['Rice_Polygon_Landsat_Extract.csv', 'Rice_Polygon_Landsat_Extract_MaxMinMean.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Rice' with 'polygon' in Sentinel2_VIs:\n",
      " ['Rice_Polygon_Sentinel2_Extract.csv', 'Rice_Polygon_Sentinel2_Extract_maxminmean.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Rice' with 'polygon' in GEE_VIs:\n",
      " ['VIs_Combined_Rice_Polygon.csv', 'VIs_Landsat_Rice_Polygons.csv', 'VIs_Sentinel2_Rice_Polygons.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Rice' with 'polygon' in Drone_VIs:\n",
      " ['Rice_Polygon_Drone_Extract.csv', 'Rice_Polygon_Drone_Extract_maxminmean.csv']\n",
      "\n",
      "Rows loaded:\n",
      "Landsat: 866, Sentinel2: 720, Satellite: 1400, Drone: 20\n",
      "\n",
      "All 'Date' values parsed successfully in Landsat data.\n",
      "All 'Date' values parsed successfully in Sentinel2 data.\n",
      "All 'Date' values parsed successfully in Satellite data.\n",
      "All 'Date' values parsed successfully in Drone data.\n",
      "Combined CSV for 'Rice' saved to: A4I064_Rice_Combined_VIs_for_ML.csv\n",
      "Total rows in combined file for 'Rice': 3006\n",
      "\n",
      "Processing crop: Mango\n",
      "\n",
      "Multiple CSV files found for crop 'Mango' with 'polygon' in Landsat_VIs:\n",
      " ['Mango_Polygon_Landsat_Extract.csv', 'Mango_Polygon_Landsat_Extract_MaxMinMean.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Mango' with 'polygon' in Sentinel2_VIs:\n",
      " ['Mango_Polygon_Sentinel2_Extract.csv', 'Mango_Polygon_Sentinel2_Extract_maxminmean.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Mango' with 'polygon' in GEE_VIs:\n",
      " ['VIs_Combined_Mango_Polygon.csv', 'VIs_Landsat_Mango_Polygons.csv', 'VIs_Sentinel2_Mango_Polygons.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Mango' with 'polygon' in Drone_VIs:\n",
      " ['Mango_Polygon_Drone_Extract.csv', 'Mango_Polygon_Drone_Extract_maxminmean.csv']\n",
      "\n",
      "Rows loaded:\n",
      "Landsat: 1180, Sentinel2: 1080, Satellite: 1440, Drone: 34\n",
      "\n",
      "All 'Date' values parsed successfully in Landsat data.\n",
      "All 'Date' values parsed successfully in Sentinel2 data.\n",
      "All 'Date' values parsed successfully in Satellite data.\n",
      "All 'Date' values parsed successfully in Drone data.\n",
      "Combined CSV for 'Mango' saved to: A4I064_Mango_Combined_VIs_for_ML.csv\n",
      "Total rows in combined file for 'Mango': 3734\n",
      "\n",
      "Processing crop: Dragonfruit\n",
      "\n",
      "Multiple CSV files found for crop 'Dragonfruit' with 'polygon' in Landsat_VIs:\n",
      " ['Dragonfruit_Polygon_Landsat_Extract.csv', 'Dragonfruit_Polygon_Landsat_Extract_MaxMinMean.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Dragonfruit' with 'polygon' in Sentinel2_VIs:\n",
      " ['Dragonfruit_Polygon_Sentinel2_Extract.csv', 'Dragonfruit_Polygon_Sentinel2_Extract_maxminmean.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Dragonfruit' with 'polygon' in GEE_VIs:\n",
      " ['VIs_Combined_Dragonfruit_Polygon.csv', 'VIs_Landsat_Dragonfruit_Polygons.csv', 'VIs_Sentinel2_Dragonfruit_Polygons.csv']\n",
      "\n",
      "Multiple CSV files found for crop 'Dragonfruit' with 'polygon' in Drone_VIs:\n",
      " ['Dragonfruit_Polygon_Drone_Extract.csv', 'Dragonfruit_Polygon_Drone_Extract_maxminmean.csv']\n",
      "\n",
      "Rows loaded:\n",
      "Landsat: 1200, Sentinel2: 780, Satellite: 1680, Drone: 24\n",
      "\n",
      "All 'Date' values parsed successfully in Landsat data.\n",
      "All 'Date' values parsed successfully in Sentinel2 data.\n",
      "All 'Date' values parsed successfully in Satellite data.\n",
      "All 'Date' values parsed successfully in Drone data.\n",
      "Combined CSV for 'Dragonfruit' saved to: A4I064_Dragonfruit_Combined_VIs_for_ML.csv\n",
      "Total rows in combined file for 'Dragonfruit': 3684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "for crop_name in crop_names:\n",
    "    print(f\"Processing crop: {crop_name}\\n\")\n",
    "\n",
    "    # Find CSV files\n",
    "    landsat_csv_path = find_crop_csv(input_folder_landsat, crop_name)\n",
    "    sentinel2_csv_path = find_crop_csv(input_folder_sentinel2, crop_name)\n",
    "    satellite_csv_path = find_crop_csv(input_folder_satellite, crop_name)\n",
    "    drone_csv_path = find_crop_csv(input_folder_drone, crop_name)\n",
    "\n",
    "    # Load DataFrames or empty if missing\n",
    "    df_satellite = pd.read_csv(satellite_csv_path) if satellite_csv_path else pd.DataFrame()\n",
    "    df_drone = pd.read_csv(drone_csv_path) if drone_csv_path else pd.DataFrame()\n",
    "    df_landsat = pd.read_csv(landsat_csv_path) if landsat_csv_path else pd.DataFrame()\n",
    "    df_sentinel2 = pd.read_csv(sentinel2_csv_path) if sentinel2_csv_path else pd.DataFrame()\n",
    "\n",
    "    print(f\"Rows loaded:\\nLandsat: {len(df_landsat)}, Sentinel2: {len(df_sentinel2)}, Satellite: {len(df_satellite)}, Drone: {len(df_drone)}\\n\")\n",
    "\n",
    "    # Skip if all empty\n",
    "    if all(df.empty for df in [df_satellite, df_drone, df_landsat, df_sentinel2]):\n",
    "        print(f\"No data found for {crop_name}. Skipping.\\n\")\n",
    "        continue\n",
    "\n",
    "    # Assign Source column\n",
    "    if not df_satellite.empty:\n",
    "        df_satellite['Source'] = df_satellite['Source'].astype(str).apply(lambda x: x if x.endswith('-GEE') else x + '-GEE')\n",
    "    if not df_drone.empty:\n",
    "        df_drone['Source'] = 'Drone'\n",
    "    if not df_landsat.empty:\n",
    "        df_landsat['Source'] = 'Landsat'\n",
    "    if not df_sentinel2.empty:\n",
    "        df_sentinel2['Source'] = 'Sentinel2'\n",
    "\n",
    "    # Process dates for each DataFrame\n",
    "    df_landsat = process_dates(df_landsat, 'Landsat', date_format=None, dayfirst=True, crop_name=crop_name)\n",
    "    df_sentinel2 = process_dates(df_sentinel2, 'Sentinel2', date_format=None, dayfirst=True, crop_name=crop_name)\n",
    "    df_satellite = process_dates(df_satellite, 'Satellite', date_format=None, dayfirst=True, crop_name=crop_name)\n",
    "    df_drone = process_dates(df_drone, 'Drone', date_format='%Y%m%d', dayfirst=False, crop_name=crop_name)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat([df_satellite, df_drone, df_landsat, df_sentinel2], ignore_index=True)\n",
    "\n",
    "    # Ensure latitude and longitude are numeric\n",
    "    for col in ['latitude', 'longitude']:\n",
    "        if col in combined_df.columns:\n",
    "            combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
    "\n",
    "    # Merge ID into Plot_ID: Plot_ID gets priority\n",
    "    if 'Plot_ID' in combined_df.columns and 'ID' in combined_df.columns:\n",
    "        combined_df['Plot_ID'] = combined_df['Plot_ID'].combine_first(combined_df['ID'])\n",
    "\n",
    "    # Drop unwanted ID columns\n",
    "    for col in ['ID', 'ML_ID']:\n",
    "        if col in combined_df.columns:\n",
    "            combined_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # Sort by Plot_ID and Date\n",
    "    if 'Plot_ID' in combined_df.columns and 'Date' in combined_df.columns:\n",
    "        combined_df = combined_df.sort_values(by=['Plot_ID', 'Date']).reset_index(drop=True)\n",
    "\n",
    "    # Save combined DataFrame to CSV\n",
    "    output_filename = f\"A4I064_{crop_name}_Combined_VIs_for_ML.csv\"\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Combined CSV for '{crop_name}' saved to: {os.path.basename(output_path)}\")\n",
    "    print(f\"Total rows in combined file for '{crop_name}': {len(combined_df)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
