{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d141f8-5f74-42e5-b039-786da2871fe7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This code extracts the values of the 14 VIs at identified field polygons (one crop at a time) from the drone data (VI tiff files). It then averages the VI values for that polygon identified by the ID and creates two csv files - the first with the average values of the VIs and the second with the maximum, minimum and mean values of the VIs within each crop polygon. The field point polygons (shapefiles) are different for the three crops and need to be read in accordingly along with the other input files. All the calculations are done locally. No temporary folders are created during execution of the code. The output csv files are saved inside the input folder as crop_Polygon_Drone_Extract.csv which contains the mean VI values (eg. Rice_Polygon_Drone_Extract.csv) and as crop_Polygon_Drone_Extract_maxminmean.csv (eg. Rice_Drone_Landsat_Extract_maxminmean.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4beabc3-bd33-4317-b354-72158e323df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment name: A4I064-ML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# This gives the name of the environment directory\n",
    "print(\"Environment name:\", os.path.basename(sys.prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fddb24-ed9d-4fa8-a436-e1088b504aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipfile is already installed.\n",
      "glob is already installed.\n",
      "rasterio is already installed.\n",
      "geopandas is already installed.\n",
      "datetime is already installed.\n",
      "re is already installed.\n",
      "shutil is already installed.\n",
      "All packages have been installed!\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages, if needed\n",
    "\n",
    "required_packages = [\"zipfile\", \"glob\", \"rasterio\", \"geopandas\", \"datetime\", \"re\", \"shutil\"]\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package if package != \"scikit-learn\" else \"sklearn\")\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"All packages have been installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77723f41-89ab-4605-9b02-c073974d2776",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import tempfile\n",
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rasterio.mask import mask\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6023d00-7fea-4b69-85b5-1beaa6280e57",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Folder setup\n",
    "source_folder = r\"C:\\Users\\U8019357\\UniSQ\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\1 - Image Processing\\Processed_Drone_VI_TIFFs\"\n",
    "\n",
    "# Enter crop name\n",
    "crop_name = \"Dragonfruit\"\n",
    "\n",
    "# Path to the folder containing the farm polygons\n",
    "shapefile_folder = r\"C:\\Users\\U8019357\\UniSQ\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\1 - Image Processing\\Raw Data\\GIS Maps and Shapefiles\\Field Polygons Final\"\n",
    "\n",
    "# Output folder to save extracted VIs\n",
    "output_folder = r\"C:\\Users\\U8019357\\UniSQ\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\2 - ML\\Raw Data\\Drone_VIs\"\n",
    "\n",
    "# Path to cycle dates CSV\n",
    "cycle_dates_csv = os.path.join(source_folder, \"Drone_cycle_dates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef64bfc-75bc-46fb-8d7e-9a1f2376c6c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\U8019357\\\\UniSQ\\\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\\\1 - Image Processing\\\\Processed_Drone_VI_TIFFs\\\\Drone_cycle_dates.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m gdf_centroid = gdf.to_crs(epsg=\u001b[32m4326\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load cycle date info\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m cycle_dates_df = pd.read_csv(cycle_dates_csv)\n\u001b[32m     13\u001b[39m cycle_dates_df.columns = cycle_dates_df.columns.str.strip()\n\u001b[32m     14\u001b[39m cycle_dates_df[\u001b[33m\"\u001b[39m\u001b[33mProvince\u001b[39m\u001b[33m\"\u001b[39m] = cycle_dates_df[\u001b[33m\"\u001b[39m\u001b[33mProvince\u001b[39m\u001b[33m\"\u001b[39m].str.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\A4I064-ML\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\A4I064-ML\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = TextFileReader(filepath_or_buffer, **kwds)\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\A4I064-ML\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28mself\u001b[39m._make_engine(f, \u001b[38;5;28mself\u001b[39m.engine)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\A4I064-ML\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = get_handle(\n\u001b[32m   1881\u001b[39m     f,\n\u001b[32m   1882\u001b[39m     mode,\n\u001b[32m   1883\u001b[39m     encoding=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1884\u001b[39m     compression=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1885\u001b[39m     memory_map=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mmemory_map\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m   1886\u001b[39m     is_text=is_text,\n\u001b[32m   1887\u001b[39m     errors=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mencoding_errors\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1888\u001b[39m     storage_options=\u001b[38;5;28mself\u001b[39m.options.get(\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m   1889\u001b[39m )\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\A4I064-ML\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\U8019357\\\\UniSQ\\\\A4I Geospatial Tech - UniSQ Internal - UniSQ Internal\\\\1 - Image Processing\\\\Processed_Drone_VI_TIFFs\\\\Drone_cycle_dates.csv'"
     ]
    }
   ],
   "source": [
    "# Load polygon shapefile\n",
    "shapefile_path = os.path.join(shapefile_folder, f\"{crop_name}.shp\")\n",
    "\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "gdf = gdf[~gdf.geometry.is_empty].copy()\n",
    "gdf = gdf[gdf.geometry.type.isin(['Polygon', 'MultiPolygon'])].copy()\n",
    "\n",
    "# Reproject shapefile to EPSG:4326 for centroid coordinates\n",
    "gdf_centroid = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Load cycle date info\n",
    "cycle_dates_df = pd.read_csv(cycle_dates_csv)\n",
    "cycle_dates_df.columns = cycle_dates_df.columns.str.strip()\n",
    "cycle_dates_df[\"Province\"] = cycle_dates_df[\"Province\"].str.strip()\n",
    "cycle_dates_df[\"Crop\"] = cycle_dates_df[\"Crop\"].str.strip()\n",
    "cycle_dates_df[\"Cycle\"] = cycle_dates_df[\"Cycle\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa6d21-38a2-4b01-9502-4f6a413b0ead",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify all folders for the crop\n",
    "all_folders = [f for f in os.listdir(source_folder) if os.path.isdir(os.path.join(source_folder, f))]\n",
    "crop_folders = [f for f in all_folders if crop_name.lower() in f.lower()]\n",
    "\n",
    "print(f\"Found {len(crop_folders)} folders for crop '{crop_name}'.\")\n",
    "print(crop_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e98c8-2223-4e64-a70f-e33a49c18b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vegetation Indices\n",
    "vi_list = [\"ARI\", \"CIG\", \"DVI\", \"EVI\", \"GNDVI\", \"MSAVI\", \"NDVI\", \"NDWI\", \"PRI\", \"RVI\", \"SAVI\", \"TVI\", \"VARI\", \"WDRVI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f23a9-3f0f-4d91-b9e1-76d9b020fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main data extraction loop\n",
    "\n",
    "# Prepare lists to collect results\n",
    "all_mean_records = []\n",
    "all_minmaxmean_records = []\n",
    "\n",
    "# Loop through crop folders\n",
    "for folder_name in tqdm(crop_folders, desc=\"Processing folders\"):\n",
    "    folder_path = os.path.join(source_folder, folder_name)\n",
    "    gr2_path = os.path.join(folder_path, \"Gr2Indices\")\n",
    "\n",
    "    # Parse Province, Crop, Cycle from folder name\n",
    "    parts = folder_name.split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        print(f\"Skipping folder with unexpected name format: {folder_name}\")\n",
    "        continue\n",
    "    province, crop = parts[0], parts[1]\n",
    "    if len(parts) == 4 and parts[2].lower() == \"cycle\":\n",
    "        cycle_number = parts[3]\n",
    "    else:\n",
    "        cycle_number = ''.join(filter(str.isdigit, parts[2]))\n",
    "    if not cycle_number:\n",
    "        print(f\"Skipping folder with invalid cycle info: {folder_name}\")\n",
    "        continue\n",
    "    cycle = f\"C{cycle_number}\"\n",
    "\n",
    "    # Get date from cycle_dates_df\n",
    "    date_row = cycle_dates_df[\n",
    "        (cycle_dates_df[\"Province\"].str.upper() == province.upper()) &\n",
    "        (cycle_dates_df[\"Crop\"].str.lower() == crop.lower()) &\n",
    "        (cycle_dates_df[\"Cycle\"].str.upper() == cycle.upper())\n",
    "    ]\n",
    "    \n",
    "    if date_row.empty:\n",
    "        print(f\"Date not found for {folder_name}.\")\n",
    "        continue\n",
    "    date_value = date_row.iloc[0][\"Date\"]\n",
    "\n",
    "    # Check Gr2Indices folder\n",
    "    if not os.path.exists(gr2_path):\n",
    "        print(f\"Gr2Indices folder missing in {folder_name}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Read first VI raster for CRS reference\n",
    "    sample_vi_file = os.path.join(gr2_path, f\"DJIP4M_{folder_name}_ARI.tif\")\n",
    "    if not os.path.exists(sample_vi_file):\n",
    "        print(f\"Sample VI TIFF missing for {folder_name}, skipping.\")\n",
    "        continue\n",
    "    with rasterio.open(sample_vi_file) as src:\n",
    "        raster_crs = src.crs\n",
    "        raster_bounds = src.bounds\n",
    "\n",
    "    # Reproject polygon shapefile to match raster CRS\n",
    "    if gdf.crs != raster_crs:\n",
    "        gdf_raster = gdf.to_crs(raster_crs)\n",
    "    else:\n",
    "        gdf_raster = gdf.copy()\n",
    "\n",
    "    # Loop through each polygon\n",
    "    for idx, row in gdf_raster.iterrows():\n",
    "        poly_geom = [row.geometry]\n",
    "        centroid_row = gdf_centroid.iloc[idx]\n",
    "\n",
    "        record_mean = {\n",
    "            \"ID\": row.get(\"Name\", row.get(\"CodeGPS\", f\"Polygon_{idx}\")),\n",
    "            \"latitude\": centroid_row.geometry.centroid.y,\n",
    "            \"longitude\": centroid_row.geometry.centroid.x,\n",
    "            \"Date\": date_value\n",
    "        }\n",
    "        record_minmaxmean = record_mean.copy()\n",
    "        polygon_has_data = False\n",
    "\n",
    "        # Extract VI values\n",
    "        for vi in vi_list:\n",
    "            vi_file = os.path.join(gr2_path, f\"DJIP4M_{folder_name}_{vi}.tif\")\n",
    "            if not os.path.exists(vi_file):\n",
    "                record_mean[vi] = np.nan\n",
    "                record_minmaxmean[f\"Mean{vi}\"] = np.nan\n",
    "                record_minmaxmean[f\"Min{vi}\"] = np.nan\n",
    "                record_minmaxmean[f\"Max{vi}\"] = np.nan\n",
    "                continue\n",
    "\n",
    "            with rasterio.open(vi_file) as src:\n",
    "                try:\n",
    "                    out_image, out_transform = mask(src, poly_geom, crop=True)\n",
    "                    out_image = out_image.astype(float)\n",
    "                    out_image[out_image == src.nodata] = np.nan\n",
    "                    if not np.isnan(out_image).all():\n",
    "                        polygon_has_data = True\n",
    "                except ValueError:\n",
    "                    out_image = np.full((1,1,1), np.nan)\n",
    "\n",
    "            mean_val = np.nanmean(out_image)\n",
    "            min_val = np.nanmin(out_image)\n",
    "            max_val = np.nanmax(out_image)\n",
    "\n",
    "            record_mean[vi] = mean_val\n",
    "            record_minmaxmean[f\"Mean{vi}\"] = mean_val\n",
    "            record_minmaxmean[f\"Min{vi}\"] = min_val\n",
    "            record_minmaxmean[f\"Max{vi}\"] = max_val\n",
    "\n",
    "        if polygon_has_data:\n",
    "            all_mean_records.append(record_mean)\n",
    "            all_minmaxmean_records.append(record_minmaxmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366e4db-6a27-43f7-99c5-50dbe6b46b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames\n",
    "df_mean = pd.DataFrame(all_mean_records)\n",
    "df_minmaxmean = pd.DataFrame(all_minmaxmean_records)\n",
    "\n",
    "# Add Crop and Source columns\n",
    "df_mean['Crop'] = crop_name\n",
    "df_mean['Source'] = 'Drone'\n",
    "df_minmaxmean['Crop'] = crop_name\n",
    "df_minmaxmean['Source'] = 'Drone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e40876-3c59-4d66-ae21-3bbbfb2da486",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save CSVs\n",
    "output_mean_csv = os.path.join(output_folder, f\"{crop_name}_Polygon_Drone_Extract.csv\")\n",
    "output_minmaxmean_csv = os.path.join(output_folder, f\"{crop_name}_Polygon_Drone_Extract_MaxMinMean.csv\")\n",
    "\n",
    "df_mean.to_csv(output_mean_csv, index=False)\n",
    "df_minmaxmean.to_csv(output_minmaxmean_csv, index=False)\n",
    "\n",
    "print(\"\\nExtraction completed successfully.\")\n",
    "print(f\"Mean values CSV: {os.path.abspath(output_mean_csv)}\")\n",
    "print(f\"Min-Max-Mean values CSV: {os.path.abspath(output_minmaxmean_csv)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
